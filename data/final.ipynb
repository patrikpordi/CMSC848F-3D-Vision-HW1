{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch3d.renderer import (\n",
    "    AlphaCompositor,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    PointsRasterizationSettings,\n",
    "    PointsRenderer,\n",
    "    PointsRasterizer,\n",
    "    HardPhongShader,\n",
    ")\n",
    "from pytorch3d.io import load_obj\n",
    "import pytorch3d\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm.auto import tqdm\n",
    "import mcubes\n",
    "import pickle\n",
    "\n",
    "def get_mesh_renderer(image_size=512, lights=None, device=None):\n",
    "    \"\"\"\n",
    "    Returns a Pytorch3D Mesh Renderer.\n",
    "\n",
    "    Args:\n",
    "        image_size (int): The rendered image size.\n",
    "        lights: A default Pytorch3D lights object.\n",
    "        device (torch.device): The torch device to use (CPU or GPU). If not specified,\n",
    "            will automatically use GPU if available, otherwise CPU.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            \n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            \n",
    "    raster_settings = RasterizationSettings(\n",
    "        image_size=image_size, blur_radius=0.0, faces_per_pixel=1,\n",
    "    )\n",
    "    renderer = MeshRenderer(\n",
    "        rasterizer=MeshRasterizer(raster_settings=raster_settings),\n",
    "        shader=HardPhongShader(device=device, lights=lights),\n",
    "    )\n",
    "    return renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCowRenderer:\n",
    "    def __init__(self, path=\"data/cow.obj\",image_size=512, \n",
    "                 color=[0.7, 0.7, 1],device=None):\n",
    "        self.path = path\n",
    "        self.image_size = image_size\n",
    "        self.color = color\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda:0\")\n",
    "                print(\"Using CUDA\")\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")\n",
    "                print(\"Using CPU\")\n",
    "        self.renderer = self.get_mesh_renderer(image_size=self.image_size,device=self.device)\n",
    "        self.lights = pytorch3d.renderer.PointLights(location=[[0, 0, -3]], device=self.device)\n",
    "        self.cameras = None\n",
    "        self.mesh = None\n",
    "        self.textured_mesh=None\n",
    "        self.load_mesh()\n",
    "        self.dolly_mesh = pytorch3d.io.load_objs_as_meshes([\"/home/pordipatrik/UMD/II/3D Vision/hw_1/cow_on_plane.obj\"])\n",
    "        self.rotate_mesh=pytorch3d.io.load_objs_as_meshes([])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def get_mesh_renderer(self, image_size=512, lights=None, device=None):\n",
    "        \"\"\"\n",
    "        Returns a Pytorch3D Mesh Renderer.\n",
    "\n",
    "        Args:\n",
    "            image_size (int): The rendered image size.\n",
    "            lights: A default Pytorch3D lights object.\n",
    "            device (torch.device): The torch device to use (CPU or GPU). If not specified,\n",
    "                will automatically use GPU if available, otherwise CPU.\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device(\"cuda:0\")\n",
    "                \n",
    "            else:\n",
    "                device = torch.device(\"cpu\")\n",
    "                \n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=image_size, blur_radius=0.0, faces_per_pixel=1,\n",
    "        )\n",
    "        renderer = MeshRenderer(\n",
    "            rasterizer=MeshRasterizer(raster_settings=raster_settings),\n",
    "            shader=HardPhongShader(device=device, lights=lights),\n",
    "        )\n",
    "        return renderer\n",
    "    def load_mesh(self):\n",
    "        vertices, faces, _ = load_obj(self.path)\n",
    "        faces = faces.verts_idx\n",
    "        vertices = vertices.unsqueeze(0)\n",
    "        faces = faces.unsqueeze(0)\n",
    "        textures = torch.ones_like(vertices)\n",
    "        textures = textures * torch.tensor(self.color)\n",
    "        mesh = pytorch3d.structures.Meshes(\n",
    "            verts=vertices,\n",
    "            faces=faces,\n",
    "            textures=pytorch3d.renderer.TexturesVertex(textures)\n",
    "        )\n",
    "        self.mesh = mesh\n",
    "\n",
    "        ## Color the mesh\n",
    "        color_1=[1, 0, 0]\n",
    "        color_2=[0.0, 0.0, 1]\n",
    "        # print(\"c\",color_1.shape)\n",
    "        \n",
    "        z_coordinates = vertices[:,:, 2]\n",
    "\n",
    "        # Find the largest and smallest z-coordinates\n",
    "        largest_z = torch.max(z_coordinates)\n",
    "        smallest_z = torch.min(z_coordinates)\n",
    "\n",
    "        alpha = (z_coordinates - smallest_z) / (largest_z - smallest_z)\n",
    "        textures = torch.ones_like(vertices)  # (1, N_v, 3)\n",
    "\n",
    "        color_11=textures * torch.tensor(color_1)\n",
    "        color_22=textures * torch.tensor(color_2)\n",
    "        \n",
    "        alpha=alpha.unsqueeze(2).expand(-1, -1, 3)\n",
    "\n",
    "        colorr = alpha * color_22 + (1 - alpha) * color_11\n",
    "        \n",
    "        mesh = pytorch3d.structures.Meshes(\n",
    "            verts=vertices,\n",
    "            faces=faces,\n",
    "            textures=pytorch3d.renderer.TexturesVertex(colorr),\n",
    "        )\n",
    "        self.textured_mesh = mesh\n",
    "\n",
    "    def generate_mesh(self,types=\"cow\"):\n",
    "        if types==\"cow\":\n",
    "            mesh=self.mesh.to(self.device)\n",
    "            output_file=\"results/my_cow_mesh.png\"\n",
    "        elif types==\"colored\":\n",
    "            mesh=self.textured_mesh.to(self.device)\n",
    "            output_file=\"results/textured_mesh.png\"\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(\n",
    "        R=torch.eye(3).unsqueeze(0),\n",
    "        T=torch.tensor([[0, 0, 3]]),\n",
    "        fov=60,device=self.device)\n",
    "        rend = self.renderer(mesh, device=self.device, cameras=cameras, lights=self.lights)\n",
    "        rend = rend.cpu().numpy()[0, ..., :3]  # (B, H, W, 4) -> (H, W, 3)\n",
    "        plt.imsave(output_file,rend)\n",
    "        \n",
    "    def generate_turntable_views(self, num_views=36,types=\"cow\"):\n",
    "        # Generate evenly spaced azimuth angles\n",
    "        azimuths = torch.linspace(0, 360, num_views)\n",
    "        if types==\"cow\":\n",
    "            mesh=self.mesh.to(self.device)\n",
    "            output_file=\"results/my_cow_turntable.gif\"\n",
    "        elif types==\"dolly\":\n",
    "            mesh  = self.dolly_mesh.to(self.device)\n",
    "            output_file=\"results/my_dolly_turntable.gif\"\n",
    "        elif types==\"colored\":\n",
    "            mesh=self.textured_mesh.to(self.device)\n",
    "            output_file=\"results/colored_turntable.png\"\n",
    "        \n",
    "        # Fixed elevation and distance\n",
    "        elevations = torch.tensor([30.0] * num_views)  # Fixed elevation\n",
    "        distances = torch.tensor([3.0] * num_views)    # Fixed distance\n",
    "        \n",
    "        # Generate views using look_at_view_transform\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(distances, elevations, azimuths)\n",
    "        # print(R.unsqueeze(0))\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(\n",
    "        R=R,\n",
    "        T=T,\n",
    "        fov=60,\n",
    "        device=self.device)\n",
    "        #Render images for each view\n",
    "        images=[]\n",
    "        for i in cameras:\n",
    "            img=(self.renderer(mesh,device=self.device, cameras=i, lights=self.lights))\n",
    "            img=img.cpu().numpy()[0, ..., :3]\n",
    "            images.append(img)\n",
    "        \n",
    "        images_pil = [Image.fromarray((img * 255).astype(np.uint8)) for img in images]\n",
    "        imageio.mimsave(output_file, images_pil, duration=30, loop=0)\n",
    "    \n",
    "    def generate_dolly(self,image_size=256,\n",
    "    num_frames=20,\n",
    "    duration=3,\n",
    "    device=None,\n",
    "    output_file=\"results/my_dolly.gif\",\n",
    "    ):\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda:0\")\n",
    "\n",
    "        mesh  = self.dolly_mesh .to(device)\n",
    "        \n",
    "        renderer = get_mesh_renderer(image_size=image_size, device=device)\n",
    "        lights = pytorch3d.renderer.PointLights(location=[[0.0, 0.0, -3.0]], device=device)\n",
    "\n",
    "        fovs = torch.linspace(5, 120, num_frames)\n",
    "\n",
    "        renders = []\n",
    "        for fov in tqdm(fovs):\n",
    "            distance = 5/(2*np.tan(np.radians(fov/2)))  # TODO: change this.\n",
    "            # distance = 5  # TODO: change this.\n",
    "            # T = [[0, 0, 2]]  # TODO: Change this.\n",
    "            T = [[0, 0, distance]]\n",
    "            cameras = pytorch3d.renderer.FoVPerspectiveCameras(fov=fov, T=T, device=device)\n",
    "            rend = renderer(mesh, cameras=cameras, lights=lights)\n",
    "            rend = rend[0, ..., :3].cpu().numpy()  # (N, H, W, 3)\n",
    "            renders.append(rend)\n",
    "\n",
    "        images = []\n",
    "        for i, r in enumerate(renders):\n",
    "            image = Image.fromarray((r * 255).astype(np.uint8))\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            draw.text((20, 20), f\"fov: {fovs[i]:.2f}\", fill=(255, 0, 0))\n",
    "            images.append(np.array(image))\n",
    "        imageio.mimsave(output_file, images, duration=200, loop=0)\n",
    "    \n",
    "    def_rotate_cow(self):\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "cow_renderer = MyCowRenderer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cow_renderer.generate_mesh()\n",
    "cow_renderer.generate_mesh(types=\"colored\")\n",
    "cow_renderer.generate_turntable_views(types=\"colored\")\n",
    "cow_renderer.generate_turntable_views(types=\"cow\")\n",
    "cow_renderer.generate_turntable_views(types=\"dolly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba4de7947ff4d1d9c9c1ad30f65aec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cow_renderer.generate_dolly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #1.\n",
    "    # R_relative=[[0, 1, 0], [-1, 0, 0], [0, 0, 1]]\n",
    "    # T_relative=[0, 0, 0]\n",
    "\n",
    "    #2.\n",
    "    R_relative=[[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "    T_relative=[0, 0, 3]\n",
    "\n",
    "    # # #3.\n",
    "    # R_relative=[[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "    # T_relative=[0.6, -0.5, 0]\n",
    "\n",
    "    # #4.\n",
    "    # R_relative=[[0, 0, -1], [0, 1, 0], [1, 0, 0]]\n",
    "    # T_relative=[0, 0, 3]\n",
    "    #torch tensornal no shift in z\n",
    "\n",
    "    R_relative = torch.tensor(R_relative).float()\n",
    "    T_relative = torch.tensor(T_relative).float()\n",
    "    R = R_relative @ torch.tensor([[1.0, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    T = R_relative @ torch.tensor([0.0, 0, 3]) + T_relative\n",
    "\n",
    "    # # Prepare the camera:\n",
    "    # cameras = pytorch3d.renderer.FoVPerspectiveCameras(\n",
    "    # R=torch.eye(3).unsqueeze(0),\n",
    "    # T=torch.tensor([[0, 0, 3]]),\n",
    "    # fov=60,\n",
    "    # device=device\n",
    "    # )\n",
    "\n",
    "     # Prepare the camera:\n",
    "    cameras = pytorch3d.renderer.FoVPerspectiveCameras(\n",
    "    R=R.t().unsqueeze(0),\n",
    "    T=T.unsqueeze(0),\n",
    "    fov=60,\n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
